{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\fmodern\fcharset0 Courier;\f2\fnil\fcharset0 Menlo-Regular;
\f3\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid1\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 repo layout\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 kemetic-voice/\

\f2 \uc0\u9500 \u9472 \u9472 
\f1  backend/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  app/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  main.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  core/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  config.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  security.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  services/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  voice_cloner.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  stt_engine.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  llm_orchestrator.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  telephony_manager.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  payment.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  routers/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  voices.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  calls.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  payment.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  whatsapp.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  health.py\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  models/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  requirements.txt\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  Dockerfile\

\f2 \uc0\u9500 \u9472 \u9472 
\f1  frontend/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  src/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  pages/\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  Dashboard.jsx\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  VoiceAgentCreator.jsx\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  CallInterface.jsx\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  App.jsx\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  index.jsx\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9500 \u9472 \u9472 
\f1  package.json\

\f2 \uc0\u9474 
\f1    
\f2 \uc0\u9492 \u9472 \u9472 
\f1  Dockerfile\

\f2 \uc0\u9500 \u9472 \u9472 
\f1  docker-compose.yml\

\f2 \uc0\u9500 \u9472 \u9472 
\f1  .env.example\

\f2 \uc0\u9500 \u9472 \u9472 
\f1  deploy.sh\

\f2 \uc0\u9492 \u9472 \u9472 
\f1  README.md
\f0\b\fs48 \
\pard\pardeftab720\sa120\partightenfactor0

\f3\b0\fs24 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/core/config.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from pydantic import BaseSettings\
from typing import Optional\
\
class Settings(BaseSettings):\
    ENV: str = "development"\
    REDIS_URL: str = "redis://redis:6379/0"\
    DATABASE_URL: str = "sqlite+aiosqlite:///./test.db"\
    TWILIO_ACCOUNT_SID: Optional[str] = None\
    TWILIO_AUTH_TOKEN: Optional[str] = None\
    TWILIO_PHONE_NUMBER: Optional[str] = None\
    WHATSAPP_TOKEN: Optional[str] = None\
    WHATSAPP_PHONE_ID: Optional[str] = None\
    M_PESA_CONSUMER_KEY: Optional[str] = None\
    M_PESA_CONSUMER_SECRET: Optional[str] = None\
    M_PESA_PASSKEY: Optional[str] = None\
    M_PESA_SHORTCODE: Optional[str] = None\
    JWT_SECRET: str = "PLACEHOLDER_JWT_SECRET"\
    API_KEYS: list[str] = ["dev-key-123"]\
    STORAGE_PATH: str = "/tmp/kemetic_voice"\
    S3_BUCKET: Optional[str] = None\
\
    class Config:\
        env_file = ".env"\
\
settings = Settings()\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/core/security.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import Header, HTTPException, Depends\
from jose import JWTError, jwt\
from datetime import datetime, timedelta\
from typing import Optional\
from .config import settings\
\
ALGORITHM = "HS256"\
\
async def verify_api_key(x_api_key: Optional[str] = Header(None)):\
    if x_api_key and x_api_key in settings.API_KEYS:\
        return True\
    raise HTTPException(401, "Invalid API Key")\
\
def create_jwt(subject: str, expires_minutes: int = 60*24*7):\
    now = datetime.utcnow()\
    payload = \{\
        "sub": subject,\
        "iat": now,\
        "exp": now + timedelta(minutes=expires_minutes)\
    \}\
    token = jwt.encode(payload, settings.JWT_SECRET, algorithm=ALGORITHM)\
    return token\
\
async def verify_jwt(authorization: Optional[str] = Header(None)):\
    if not authorization:\
        raise HTTPException(401, "Missing Authorization header")\
    try:\
        scheme, token = authorization.split()\
        if scheme.lower() != "bearer":\
            raise HTTPException(401, "Invalid auth scheme")\
        payload = jwt.decode(token, settings.JWT_SECRET, algorithms=[ALGORITHM])\
        return payload.get("sub")\
    except JWTError:\
        raise HTTPException(401, "Invalid token")\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/services/voice_cloner.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 import os\
from TTS.api import TTS\
import torch\
from pathlib import Path\
\
from ..core.config import settings\
\
class VoiceCloner:\
    def __init__(self):\
        self.device = "cuda" if torch.cuda.is_available() else "cpu"\
        # Load a lightweight TTS model; for production replace with a hosted model server\
        try:\
            self.tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")\
            # The TTS API may be CPU-only; .to() not supported in some versions; leave as-is\
        except Exception as e:\
            print("TTS model load failed (you may want to run with GPU or an inference server):", e)\
            self.tts = None\
\
        Path(settings.STORAGE_PATH).mkdir(parents=True, exist_ok=True)\
\
    async def clone_voice(self, voice_id: str, uploaded_file_path: str, name: str, language: str):\
        """\
        Takes an uploaded sample file path already saved on disk and creates a speaker file used for synthesis.\
        Returns metadata with the path to the stored speaker file.\
        """\
        # Ensure path exists\
        if not os.path.exists(uploaded_file_path):\
            raise FileNotFoundError("uploaded audio file not found")\
\
        speaker_dest = os.path.join(settings.STORAGE_PATH, f"\{voice_id\}.wav")\
        # Normalize/convert file if needed (ffmpeg could be used here). For simplicity, copy.\
        with open(uploaded_file_path, "rb") as src, open(speaker_dest, "wb") as dst:\
            dst.write(src.read())\
\
        return \{"name": name, "language": language, "path": speaker_dest\}\
\
    async def synthesize_speech(self, text: str, voice_id: str = "default") -> bytes:\
        speaker_wav = None\
        if voice_id != "default":\
            candidate = os.path.join(settings.STORAGE_PATH, f"\{voice_id\}.wav")\
            if os.path.exists(candidate):\
                speaker_wav = candidate\
\
        out_path = os.path.join(settings.STORAGE_PATH, f"out_\{voice_id\}.wav")\
\
        if self.tts is None:\
            # fallback: simple gTTS or placeholder\
            raise RuntimeError("TTS engine not available. Consider provisioning a model server.")\
\
        # The TTS library returns or writes to disk depending on version\
        try:\
            self.tts.tts_to_file(text=text, speaker_wav=speaker_wav, language=None, file_path=out_path)\
        except TypeError:\
            # older/newer versions differences\
            self.tts.tts_to_file(text, speaker_wav=speaker_wav, file_path=out_path)\
\
        with open(out_path, "rb") as f:\
            return f.read()\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/services/stt_engine.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from transformers import WhisperProcessor, WhisperForConditionalGeneration\
import torch\
import soundfile as sf\
import numpy as np\
from io import BytesIO\
\
class STTEngine:\
    def __init__(self):\
        self.device = "cuda" if torch.cuda.is_available() else "cpu"\
        try:\
            self.processor = WhisperProcessor.from_pretrained("openai/whisper-small")\
            self.model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")\
            self.model.to(self.device)\
        except Exception as e:\
            print("Warning: Whisper model not loaded:", e)\
            self.processor = None\
            self.model = None\
\
    async def transcribe(self, audio_bytes: bytes) -> str:\
        if self.processor is None or self.model is None:\
            return "[stt-not-available]"\
\
        with BytesIO(audio_bytes) as b:\
            audio, sr = sf.read(b)\
            if audio.ndim > 1:\
                audio = np.mean(audio, axis=1)\
\
        input_features = self.processor(audio, sampling_rate=sr, return_tensors="pt").input_features\
        input_features = input_features.to(self.model.device)\
        predicted_ids = self.model.generate(input_features)\
        transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\
        return transcription\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/services/llm_orchestrator.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 # Minimal orchestrator that you can replace with provider calls\
from typing import Dict\
\
class LLMOrchestrator:\
    def __init__(self):\
        pass\
\
    async def process_query(self, text: str, config: Dict[str, any]):\
        # Safe default: simple rule-based echo with welcome message logic\
        welcome = config.get("welcome_message")\
        if text.strip() == "":\
            return welcome or "Habari \'97 how can I help you?"\
\
        # In production call an LLM provider here (OpenAI, Anthropic, local LLM)\
        return f"[KemetAI reply] \{text\}"\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/services/telephony_manager.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 import os\
from twilio.rest import Client\
from ..core.config import settings\
\
class TelephonyManager:\
    def __init__(self):\
        if settings.TWILIO_ACCOUNT_SID and settings.TWILIO_AUTH_TOKEN:\
            self.client = Client(settings.TWILIO_ACCOUNT_SID, settings.TWILIO_AUTH_TOKEN)\
        else:\
            self.client = None\
\
    async def initiate_call(self, to_number: str, session_id: str, agent_config: dict):\
        # For full production you'd create TwiML to stream/bridge audio\
        if self.client is None:\
            return \{"status": "twilio-not-configured"\}\
\
        call = self.client.calls.create(\
            to=to_number,\
            from_=settings.TWILIO_PHONE_NUMBER,\
            twiml=f"<Response><Say>\{agent_config.get('welcome_message','Habari')\}</Say></Response>"\
        )\
        return \{"status": "initiated", "twilio_sid": call.sid\}\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/services/payment.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 import base64\
import requests\
from datetime import datetime\
from ..core.config import settings\
\
class MpesaPayment:\
    def __init__(self):\
        self.consumer_key = settings.M_PESA_CONSUMER_KEY\
        self.consumer_secret = settings.M_PESA_CONSUMER_SECRET\
        self.shortcode = settings.M_PESA_SHORTCODE\
        self.passkey = settings.M_PESA_PASSKEY\
        self.callback_url = "https://your-public-url/api/v1/payment/callback"\
\
    def get_token(self):\
        url = "https://sandbox.safaricom.co.ke/oauth/v1/generate?grant_type=client_credentials"\
        auth = base64.b64encode(f"\{self.consumer_key\}:\{self.consumer_secret\}".encode()).decode()\
        headers = \{"Authorization": f"Basic \{auth\}"\}\
        r = requests.get(url, headers=headers)\
        r.raise_for_status()\
        return r.json().get("access_token")\
\
    def stk_push(self, phone: str, amount: int = 500):\
        token = self.get_token()\
        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\
        password = base64.b64encode(f"\{self.shortcode\}\{self.passkey\}\{timestamp\}".encode()).decode()\
\
        payload = \{\
            "BusinessShortCode": self.shortcode,\
            "Password": password,\
            "Timestamp": timestamp,\
            "TransactionType": "CustomerPayBillOnline",\
            "Amount": amount,\
            "PartyA": phone,\
            "PartyB": self.shortcode,\
            "PhoneNumber": phone,\
            "CallBackURL": self.callback_url,\
            "AccountReference": "KemetVoice",\
            "TransactionDesc": "Unlock Unlimited AI Voice & WhatsApp"\
        \}\
\
        headers = \{'Authorization': f'Bearer \{token\}', 'Content-Type': "application/json"\}\
        response = requests.post(\
            "https://sandbox.safaricom.co.ke/mpesa/stkpush/v1/processrequest",\
            json=payload, headers=headers\
        )\
        response.raise_for_status()\
        return response.json()\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/routers/voices.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import APIRouter, UploadFile, File, BackgroundTasks, HTTPException, Depends\
import uuid, os\
from ..services.voice_cloner import VoiceCloner\
from ..core.config import settings\
from ..core.security import verify_api_key\
\
router = APIRouter(prefix="/api/v1/voices", tags=["voices"])\
vc = VoiceCloner()\
\
@router.post('/clone', dependencies=[Depends(verify_api_key)])\
async def clone_voice(name: str, language: str = "en", file: UploadFile = File(...), background_tasks: BackgroundTasks = None):\
    voice_id = str(uuid.uuid4())\
    file_path = os.path.join(settings.STORAGE_PATH, f"upload_\{voice_id\}_\{file.filename\}")\
\
    with open(file_path, "wb") as f:\
        content = await file.read()\
        f.write(content)\
\
    # background processing example (for heavy processing you should use Celery)\
    result = await vc.clone_voice(voice_id, file_path, name, language)\
    return \{"voice_id": voice_id, "status": "success", **result\}\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/routers/calls.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import APIRouter, HTTPException, Depends\
from pydantic import BaseModel\
import uuid\
from ..services.telephony_manager import TelephonyManager\
from ..core.config import settings\
from ..core.security import verify_api_key\
\
router = APIRouter(prefix="/api/v1/calls", tags=["calls"])\
tele = TelephonyManager()\
\
class AgentConfig(BaseModel):\
    name: str\
    voice_id: str\
    llm_provider: str = "kemet"\
    welcome_message: str = "Habari! This is your Kemet Voice agent speaking."\
\
class CallRequest(BaseModel):\
    to_number: str\
    agent_config: AgentConfig\
\
@router.post('/initiate', dependencies=[Depends(verify_api_key)])\
async def initiate_call(request: CallRequest):\
    session_id = str(uuid.uuid4())\
    result = await tele.initiate_call(\
        to_number=request.to_number,\
        session_id=session_id,\
        agent_config=request.agent_config.dict()\
    )\
    # Store minimal session meta in Redis if needed (left as exercise)\
    return \{"session_id": session_id, **result\}\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/routers/payment.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import APIRouter, Body, Depends\
from ..services.payment import MpesaPayment\
from ..core.security import verify_api_key\
\
router = APIRouter(prefix='/api/v1/payment', tags=['payment'])\
mp = MpesaPayment()\
\
@router.post('/mpesa', dependencies=[Depends(verify_api_key)])\
async def mpesa_pay(payload: dict = Body(...)):\
    phone = payload.get('phone')\
    amount = payload.get('amount', 500)\
    return mp.stk_push(phone, amount)\
\
@router.post('/callback')\
async def mpesa_callback(body: dict = Body(...)):\
    # Implement verification & persistence here\
    # Log and respond with 200\
    return \{"status": "received"\}\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/routers/whatsapp.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import APIRouter, Request, Depends\
from ..core.security import verify_api_key\
from ..services.voice_cloner import VoiceCloner\
from ..services.llm_orchestrator import LLMOrchestrator\
import requests\
from ..core.config import settings\
\
router = APIRouter(prefix='/api/v1/whatsapp', tags=['whatsapp'])\
vc = VoiceCloner()\
llm = LLMOrchestrator()\
\
@router.post('/webhook')\
async def whatsapp_webhook(request: Request):\
    data = await request.json()\
    # Production: validate signature from Facebook/WhatsApp\
    try:\
        msg = data['entry'][0]['changes'][0]['value']['messages'][0]\
    except Exception:\
        return \{"status": "ignored"\}\
\
    from_number = msg['from']\
    text = msg.get('text', \{\}).get('body', '')\
\
    reply_text = await llm.process_query(text, \{"provider": "kemet"\})\
    audio_bytes = await vc.synthesize_speech(reply_text, voice_id='user_123')\
\
    # Upload audio to WhatsApp media endpoint (simplified)\
    media_upload = requests.post(\
        f"https://graph.facebook.com/v15.0/\{settings.WHATSAPP_PHONE_ID\}/media",\
        headers=\{"Authorization": f"Bearer \{settings.WHATSAPP_TOKEN\}"\},\
        files=\{"file": ("reply.wav", audio_bytes)\}\
    )\
    media_resp = media_upload.json()\
    media_id = media_resp.get('id')\
\
    send_resp = requests.post(\
        f"https://graph.facebook.com/v15.0/\{settings.WHATSAPP_PHONE_ID\}/messages",\
        headers=\{"Authorization": f"Bearer \{settings.WHATSAPP_TOKEN\}", "Content-Type": "application/json"\},\
        json=\{\
            "messaging_product": "whatsapp",\
            "to": from_number,\
            "type": "audio",\
            "audio": \{"id": media_id\}\
        \}\
    )\
\
    return \{"status": "sent"\}\
import requests\
\
WHATSAPP_TOKEN = settings.WHATSAPP_TOKEN\
PHONE_ID = settings.WHATSAPP_PHONE_ID\
\
def send_whatsapp_voice(to_number: str, audio_bytes: bytes):\
    # 1) upload media\
    files = \{"file": ("reply.wav", audio_bytes, "audio/wav")\}\
    params = \{"messaging_product":"whatsapp"\}\
    r = requests.post(f"https://graph.facebook.com/v15.0/\{PHONE_ID\}/media",\
                      headers=\{"Authorization": f"Bearer \{WHATSAPP_TOKEN\}"\},\
                      params=params, files=files)\
    r.raise_for_status()\
    media_id = r.json()["id"]\
\
    # 2) send message referencing media id\
    payload = \{\
        "messaging_product":"whatsapp",\
        "to": to_number,\
        "type":"audio",\
        "audio":\{"id": media_id\}\
    \}\
    r2 = requests.post(f"https://graph.facebook.com/v15.0/\{PHONE_ID\}/messages",\
                       headers=\{"Authorization": f"Bearer \{WHATSAPP_TOKEN\}",\
                                "Content-Type":"application/json"\},\
                       json=payload)\
    r2.raise_for_status()\
    return r2.json()\
\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/routers/health.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import APIRouter\
from ..core.config import settings\
\
router = APIRouter()\
\
@router.get('/api/v1/health')\
async def health():\
    return \{\
        "status": "healthy",\
        "services": \{\
            "storage_path": settings.STORAGE_PATH,\
            "twilio": bool(settings.TWILIO_ACCOUNT_SID),\
            "whatsapp": bool(settings.WHATSAPP_TOKEN),\
        \}\
    \}\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/app/main.py\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 from fastapi import FastAPI\
from fastapi.middleware.cors import CORSMiddleware\
from .routers import voices, calls, payment, whatsapp, health\
from .core.config import settings\
\
app = FastAPI(title="Kemet Voice", version="3.0.0")\
\
app.add_middleware(\
    CORSMiddleware,\
    allow_origins=["*"],\
    allow_credentials=True,\
    allow_methods=["*"],\
    allow_headers=["*"],\
)\
\
app.include_router(voices.router)\
app.include_router(calls.router)\
app.include_router(payment.router)\
app.include_router(whatsapp.router)\
app.include_router(health.router)\
\
@app.get('/')\
def root():\
    return \{"message": "Kemet Voice Sovereign AI Platform Live"\}\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 backend/requirements.txt\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 fastapi==0.95.2\
uvicorn[standard]==0.22.0\
python-multipart==0.0.6\
python-dotenv==1.0.0\
torch==2.1.1\
TTS==0.22.0\
transformers==4.35.2\
librosa==0.10.1\
soundfile==0.12.1\
twilio==8.13.0\
requests==2.31.0\
pydantic==1.10.12\
python-jose==3.3.0\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 Dockerfile (backend)\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 FROM python:3.11-slim\
WORKDIR /app\
COPY backend/requirements.txt ./\
RUN pip install --no-cache-dir -r requirements.txt\
COPY backend/app ./app\
ENV PYTHONPATH=/app\
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 docker-compose.yml\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 version: '3.8'\
services:\
  redis:\
    image: redis:7\
    ports:\
      - "6379:6379"\
  backend:\
    build: ./\
    volumes:\
      - ./backend/app:/app/app\
      - /tmp:/tmp\
    ports:\
      - "8000:8000"\
    depends_on:\
      - redis\
    environment:\
      - REDIS_URL=redis://redis:6379/0\
      - TWILIO_ACCOUNT_SID=$\{TWILIO_ACCOUNT_SID\}\
      - TWILIO_AUTH_TOKEN=$\{TWILIO_AUTH_TOKEN\}\
      - TWILIO_PHONE_NUMBER=$\{TWILIO_PHONE_NUMBER\}\
      - WHATSAPP_TOKEN=$\{WHATSAPP_TOKEN\}\
      - WHATSAPP_PHONE_ID=$\{WHATSAPP_PHONE_ID\}\
  frontend:\
    build: ./frontend\
    ports:\
      - "3000:80"\
    depends_on:\
      - backend\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 .env.example\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 ENV=production\
REDIS_URL=redis://redis:6379/0\
DATABASE_URL=sqlite+aiosqlite:///./test.db\
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxx\
TWILIO_AUTH_TOKEN=your_auth_token_here\
TWILIO_PHONE_NUMBER=+1234567890\
WHATSAPP_TOKEN=EAAG...YOUR_TOKEN\
WHATSAPP_PHONE_ID=123456789\
M_PESA_CONSUMER_KEY=YOUR_CONSUMER_KEY\
M_PESA_CONSUMER_SECRET=YOUR_CONSUMER_SECRET\
M_PESA_PASSKEY=YOUR_PASSKEY\
M_PESA_SHORTCODE=174379\
JWT_SECRET=replace_with_a_strong_secret\
API_KEYS=["dev-key-123"]\
STORAGE_PATH=/tmp/kemetic_voice\
S3_BUCKET=\
\pard\pardeftab720\sa120\partightenfactor0

\f3 \cf2 \
# pseudocode for wss endpoint handling Twilio media\
from fastapi import WebSocket\
import base64, io, soundfile as sf\
from services.stt_engine import STTEngine\
from services.llm_orchestrator import LLMOrchestrator\
from services.voice_cloner import VoiceCloner\
from twilio.rest import Client\
\
stt = STTEngine()\
llm = LLMOrchestrator()\
tts = VoiceCloner()\
twilio_client = Client(ACCOUNT_SID, AUTH_TOKEN)\
\
async def twilio_ws_handler(websocket: WebSocket, session_id: str, call_sid: str):\
    await websocket.accept()\
    buffer = b''\
    while True:\
        msg = await websocket.receive_json()\
        # Twilio sends base64 encoded audio in 'media' key\
        if 'media' in msg:\
            b64 = msg['media']['payload']\
            data = base64.b64decode(b64)\
            # feed into streaming STT buffer, do segmentation logic\
            buffer += data\
            if should_transcribe(buffer):\
                transcription = await stt.transcribe(buffer)\
                buffer = b''\
\
                reply_text = await llm.process_query(transcription, config=\{\})\
                audio_bytes = await tts.synthesize_speech(reply_text, voice_id="user_x")\
\
                # upload to S3 -> obtain public URL\
                s3_url = upload_to_s3_bytes(audio_bytes, f"responses/\{call_sid\}/\{uuid4()\}.wav")\
\
                # Play into call:\
                twilio_client.calls(call_sid).update(twiml=f"<Response><Play>\{s3_url\}</Play></Response>")\
import uuid, numpy as np\
from models.voice_model import Voice\
from sqlalchemy.ext.asyncio import AsyncSession\
\
voice_id = str(uuid.uuid4())\
emb_np = encoder.extract_embedding(local_wav_path)\
voice = Voice(id=voice_id,\
              owner_id="user123",\
              name="Gathua sample",\
              language="en",\
              file_path=s3_url,\
              embedding=emb_np.tobytes(),\
              embedding_dim=emb_np.shape[0])\
async_session.add(voice); await async_session.commit()\
# backend/app/models/voice_model.py\
from sqlalchemy import Column, String, Integer, DateTime, LargeBinary, Text\
from sqlalchemy.sql import func\
from sqlalchemy.ext.declarative import declarative_base\
\
Base = declarative_base()\
\
class Voice(Base):\
    __tablename__ = "voices"\
    id = Column(String, primary_key=True, index=True)\
    owner_id = Column(String, index=True)\
    name = Column(String)\
    language = Column(String)\
    file_path = Column(String)          # S3 path or internal path\
    embedding = Column(LargeBinary)     # raw bytes (numpy.tobytes())\
    embedding_dim = Column(Integer)\
    created_at = Column(DateTime, server_default=func.now())\
    metadata = Column(Text)             # JSON-encoded text\
from services.speaker_encoder import SpeakerEncoder\
import base64\
import numpy as np\
\
encoder = SpeakerEncoder()\
\
emb = encoder.extract_embedding("/tmp/kemetic_voice/upload_uuid_file.wav")\
# store as base64 to put into DB easily\
emb_b64 = base64.b64encode(emb.tobytes()).decode()\
# services/speaker_encoder.py\
import torch\
import numpy as np\
import soundfile as sf\
from speechbrain.pretrained import EncoderClassifier\
from pathlib import Path\
\
class SpeakerEncoder:\
    def __init__(self, device=None):\
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")\
        # loads ECAPA-TDNN speaker recognition model\
        self.model = EncoderClassifier.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb",\
                                                    savedir="pretrained_models/spkrec_ecapa",\
                                                    run_opts=\{"device": self.device\})\
\
    def extract_embedding(self, wav_path: str) -> np.ndarray:\
        wav, sr = sf.read(wav_path)\
        # model expects mono, 16k-48k ok\
        if wav.ndim > 1:\
            wav = wav.mean(axis=1)\
        embeddings = self.model.encode_file(wav_path).squeeze().cpu().numpy()  # shape (192,) typical\
        # optionally l2 normalize\
        embeddings = embeddings / np.linalg.norm(embeddings)\
        return embeddings\
\
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf2 README.md (excerpt)\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 # Kemet Voice \'97 Deployable\
\
## Quick start (development)\
\
1. Copy `.env.example` to `.env` and fill values.\
2. Build & run:\
\
```bash\
docker-compose up --build\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls1\ilvl0
\f3 \cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use the API key in 
\f1 API_KEYS
\f3  to call protected endpoints (header 
\f1 x-api-key
\f3 ).\uc0\u8232 \
}